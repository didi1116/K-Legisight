"""
build_member_stats.py
----------------------------------------
ğŸ“Œ ëª©ì :
- ì˜ì›(member_id) ë‹¨ìœ„ì˜ ì „ì²´ ìš”ì•½ í†µê³„ë¥¼ ìƒì„±í•œë‹¤.
- ì „ì²´ ë°œì–¸ì„ ê¸°ë°˜ìœ¼ë¡œ í˜‘ë ¥ë„ í‰ê· , ë°œì–¸ëŸ‰, ë²•ì•ˆ ì°¸ì—¬ ìˆ˜ ë“±ì„ ê³„ì‚°í•œë‹¤.
- UIì—ì„œ "ì˜ì› í”„ë¡œí•„"ì— í•´ë‹¹í•˜ëŠ” í•µì‹¬ ë°ì´í„°.

ğŸ“Œ ì…ë ¥:
- ./analysis_by_sen/output_member/all_speeches.pkl
  (build_member_load_data.py ì—ì„œ ìƒì„±ë¨)

ğŸ“Œ ê¸°ëŠ¥ ìš”ì•½:
1) sentiment_probì—ì„œ í˜‘ë ¥/ë¹„í˜‘ë ¥/ì¤‘ë¦½ í™•ë¥  ì¶”ì¶œ
2) score_prob ê³„ì‚° (í˜‘ë ¥ë„ = coop - noncoop)
3) ë°œì–¸ ê¸¸ì´ ê³„ì‚°
4) ì˜ì› ë‹¨ìœ„(groupby member_id)ë¡œ í†µê³„ë¥¼ ê³„ì‚°
5) í•œ ì˜ì›ì´ ì—¬ëŸ¬ ì´ë¦„(member_name)ì„ ê°€ì§„ ê²½ìš° â†’ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ì´ë¦„(mode) ì„ íƒ
6) ë§ˆì§€ë§‰ì— ì•ˆì •ì ìœ¼ë¡œ mergeí•˜ì—¬ NaN ì—†ì´ êµ¬ì„±
7) member_id ê¸°ì¤€ ì •ë ¬ í›„ CSV ì €ì¥

ğŸ“Œ ì¶œë ¥:
- ./analysis_by_sen/output_member/member_stats.csv

ğŸ“Œ ìƒì„±ë˜ëŠ” ì£¼ìš” ì»¬ëŸ¼:
- total_speeches ............ ì˜ì› ì „ì²´ ë°œì–¸ ìˆ˜
- total_speech_length ....... ë°œì–¸ ê¸¸ì´ ì´í•©
- avg_speech_length ......... ë°œì–¸ ê¸¸ì´ í‰ê· 
- avg_prob_coop ............. í‰ê·  í˜‘ë ¥ í™•ë¥ 
- avg_prob_noncoop .......... í‰ê·  ë¹„í˜‘ë ¥ í™•ë¥ 
- avg_prob_neutral .......... í‰ê·  ì¤‘ë¦½ í™•ë¥ 
- cooperation_score_prob ..... í‰ê·  í˜‘ë ¥ë„ ì ìˆ˜ (coop - noncoop)
- bills_count ............... ì˜ì›ì´ ì°¸ì—¬í•œ ê³ ìœ  ë²•ì•ˆ ìˆ˜
- controversy_rate .......... coop + noncoop (ì˜ê²¬ ê°•ë„ ì§€í‘œ)

"""

import pandas as pd
from util_common import compute_score_prob, compute_speech_length

# ----------------------------------------
# ê²½ë¡œ ì„¤ì •
# ----------------------------------------
INPUT_PICKLE = "./output_member/all_speeches.pkl"
OUTPUT_CSV   = "./output_member/member_stats.csv"

if __name__ == "__main__":

    # ---------------------------------------------------------
    # 1) ì „ì²´ ë°œì–¸ ë¡œë“œ
    # ---------------------------------------------------------
    try:
        df = pd.read_pickle(INPUT_PICKLE)
    except FileNotFoundError:
        raise FileNotFoundError(f"[ERROR] all_speeches.pkl ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {INPUT_PICKLE}")

    # ---------------------------------------------------------
    # 2) sentiment_prob â†’ ì•ˆì „í•œ í™•ë¥  ì¶”ì¶œ
    # ---------------------------------------------------------
    def get_prob(x, key):
        if isinstance(x, dict):
            return x.get(key, 0.0)
        return 1.0 if key == "neutral" else 0.0   # None â†’ neutral=1

    df["prob_noncoop"] = df["sentiment_prob"].apply(lambda x: get_prob(x, "noncoop"))
    df["prob_coop"]    = df["sentiment_prob"].apply(lambda x: get_prob(x, "coop"))
    df["prob_neutral"] = df["sentiment_prob"].apply(lambda x: get_prob(x, "neutral"))

    # ---------------------------------------------------------
    # 3) score_prob, speech_length ê³„ì‚°
    # ---------------------------------------------------------
    df["score_prob"]    = df.apply(lambda r: compute_score_prob(r["prob_coop"], r["prob_noncoop"]), axis=1)
    df["speech_length"] = df["speech_text"].apply(compute_speech_length)

    # ---------------------------------------------------------
    # 4) ì˜ì› ì´ë¦„ í†µì¼ (member_id ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ë§ì´ ë“±ì¥í•œ ì´ë¦„ ì‚¬ìš©)
    # ---------------------------------------------------------
    name_map = (
        df.groupby("member_id")["member_name"]
          .agg(lambda x: x.mode()[0] if len(x) > 0 else None)
          .to_dict()
    )

    # ---------------------------------------------------------
    # 5) ì˜ì› ë‹¨ìœ„ ê¸°ë³¸ í†µê³„ ìƒì„±
    # ---------------------------------------------------------
    basic_stats = df.groupby("member_id").agg(
        total_speeches=("speech_id", "count"),
        total_speech_length=("speech_length", "sum"),
        avg_speech_length=("speech_length", "mean"),
        avg_prob_coop=("prob_coop", "mean"),
        avg_prob_noncoop=("prob_noncoop", "mean"),
        avg_prob_neutral=("prob_neutral", "mean"),
        cooperation_score_prob=("score_prob", "mean")
    ).reset_index()

    # ---------------------------------------------------------
    # 6) ì˜ì›ì´ ì°¸ì—¬í•œ ê³ ìœ  ë²•ì•ˆ ìˆ˜ ê³„ì‚°
    # ---------------------------------------------------------
    bills_count = (
        df.groupby("member_id")["bill_review"]
        .apply(lambda x: len(set(sum(x.tolist(), []))))
        .reset_index(name="bills_count")
    )

    # ---------------------------------------------------------
    # 7) ëª¨ë‘ ë³‘í•© (member_id ê¸°ì¤€)
    # ---------------------------------------------------------
    result = (
        basic_stats
        .merge(bills_count, on="member_id", how="left")
    )

    # ì˜ì› ì´ë¦„ ë¶™ì´ê¸°
    result["member_name"] = result["member_id"].map(name_map)

    # ---------------------------------------------------------
    # 8) controversy_rate ê³„ì‚°
    # ---------------------------------------------------------
    result["controversy_rate"] = (
        result["avg_prob_coop"] + result["avg_prob_noncoop"]
    )
    # sentiment_label ì¹´ìš´íŠ¸ ì¶”ê°€
    label_counts = (
        df.groupby(["member_id", "sentiment_label"])["speech_id"]
          .count()
          .unstack(fill_value=0)
          .rename(columns={0: "count_label_0", 1: "count_label_1", 2: "count_label_2"})
    )

    result = result.merge(label_counts, on="member_id", how="left")

    # ==== Excel ì§€ìˆ˜í‘œê¸° ë°©ì§€ ì²˜ë¦¬ ====
    for col in ["avg_prob_coop", "avg_prob_noncoop", "avg_prob_neutral", "cooperation_score_prob"]:
        result[col] = result[col].apply(lambda x: f'="{x:.20f}"')

    # ---------------------------------------------------------
    # 9) ì •ë ¬ í›„ ì €ì¥
    # ---------------------------------------------------------
    result = result.sort_values("member_id")

    result.to_csv(OUTPUT_CSV, index=False, encoding="utf-8-sig")

    print("==============================================")
    print("[SUCCESS] member_stats.csv ìƒì„± ì™„ë£Œ")
    print(" â†’ ì €ì¥ ìœ„ì¹˜:", OUTPUT_CSV)
    print(" â†’ ì´ ì˜ì› ìˆ˜:", len(result))
    print("==============================================")