#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
predict_bill_pass_probability.py
========================================================================
ğŸ“Œ PURPOSE

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë²•ì•ˆ í‚¤ì›Œë“œë¥¼ ê¸°ì¤€ìœ¼ë¡œ:

1ï¸âƒ£ ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´
    ê³¼ê±°ì˜ "êµ¬ì¡°ì ìœ¼ë¡œ ìœ ì‚¬í•œ ë²•ì•ˆë“¤"ì„ ì„ ë³„í•˜ê³ 

2ï¸âƒ£ í•´ë‹¹ ë²•ì•ˆë“¤ì˜
    - ë°œì–¸ ê¸°ë°˜ í˜‘ë ¥ë„(avg_score_prob)
    - ë°œì–¸ ìˆ˜(n_speeches)
    - ì‹¤ì œ ì˜ê²° ê²°ê³¼(label: í†µê³¼=1 / ë¶ˆí†µê³¼=0)

3ï¸âƒ£ ë¥¼ **ì™„ì „íˆ ì„¤ëª… ê°€ëŠ¥í•œ ê·œì¹™ ê¸°ë°˜ ìˆ˜ì‹**ìœ¼ë¡œ ê²°í•©í•˜ì—¬

ğŸ‘‰ ë‹¤ìŒ 4ê°€ì§€ ì§€í‘œë¥¼ ë™ì‹œì— ì‚°ì¶œí•œë‹¤.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â‘  ê°€ê²° í™•ë¥  (Pass Probability)
â‘¡ ì…ë²• ê´´ë¦¬ìœ¨ (Legislative Gap)
â‘¢ ì‹ ë¢°ë„ (Confidence)
â‘£ ìì—°ì–´ ì„¤ëª… + ê·¼ê±° ë²•ì•ˆ ëª©ë¡
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âš ï¸ í•µì‹¬ ì „ì œ
- ì´ ëª¨ë¸ì€ "ë¯¸ë˜ ì˜ˆì¸¡ ëª¨ë¸"ì´ ì•„ë‹ˆë‹¤.
- ê³¼ê±° ì…ë²• íŒ¨í„´ì„ êµ¬ì¡°ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬
  "ì´ëŸ° ìœ í˜•ì˜ ë²•ì•ˆì€ ë³´í†µ ì–´ë–»ê²Œ ê·€ê²°ë˜ëŠ”ê°€"ë¥¼ ë³´ì—¬ì£¼ëŠ” ë„êµ¬ë‹¤.

âš ï¸ ê¸°ìˆ ì  ì›ì¹™
- ë¸”ë™ë°•ìŠ¤ ML ì‚¬ìš© âŒ
- ëª¨ë“  ê³„ì‚°ì€ ì‚¬ëŒì´ ì¶”ì Â·ì„¤ëª… ê°€ëŠ¥í•œ ê·œì¹™ ê¸°ë°˜ âœ”
========================================================================
"""

# ======================================================================
# IMPORTS
# ======================================================================
import os
import math
import numpy as np
import pandas as pd
from typing import Dict

from dotenv import load_dotenv
from openai import OpenAI

# ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ ë²•ì•ˆ ê²€ìƒ‰ í•¨ìˆ˜
from search_similar_bills import search_similar_bills


# ======================================================================
# PATH CONFIG
# ======================================================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
TRAIN_PKL = os.path.join(BASE_DIR, "FastAPI", "data", "processed", "bill_training_table.pkl")


# ======================================================================
# OPENAI CLIENT (ì„ë² ë”© ì „ìš©)
# ======================================================================
# â— ìì—°ì–´ ìƒì„± ëª¨ë¸ ì‚¬ìš© ê¸ˆì§€
# â— í•™ìŠµ ë‹¨ê³„ì™€ ë™ì¼í•œ ì„ë² ë”© ëª¨ë¸ë§Œ ì‚¬ìš©
load_dotenv()
client = OpenAI()


# ======================================================================
# QUERY EMBEDDING
# ======================================================================
def embed_query(text: str) -> np.ndarray:
    """
    ì‚¬ìš©ì ì…ë ¥ ë²•ì•ˆ í‚¤ì›Œë“œë¥¼
    í•™ìŠµ ë‹¨ê³„ì™€ ë™ì¼í•œ ì„ë² ë”© ëª¨ë¸ë¡œ ë²¡í„°í™”í•œë‹¤.

    ë°˜í™˜:
    - shape: (1, embedding_dim)
    """
    res = client.embeddings.create(
        model="text-embedding-3-large",
        input=text
    )
    return np.array(res.data[0].embedding).reshape(1, -1)


# ======================================================================
# WEIGHT FUNCTION
# ======================================================================
def compute_weight(
    similarity: float,
    n_speeches: int,
    avg_score_prob: float,
    alpha: float = 1.5
) -> float:
    """
    í•˜ë‚˜ì˜ ê³¼ê±° ë²•ì•ˆì´
    í˜„ì¬ ë²•ì•ˆ ì˜ˆì¸¡ì— ì–¼ë§ˆë‚˜ ì‹ ë¢°í•  ë§Œí•œ ê·¼ê±°ì¸ì§€ë¥¼ ê²°ì •í•˜ëŠ” ê°€ì¤‘ì¹˜.

    --------------------------------------------------------------
    weight =
        (ì˜ë¯¸ ìœ ì‚¬ë„)
      Ã— (ë…¼ì˜ ì¶©ë¶„ì„±)
      Ã— (ì •ì¹˜ì  ì‹ í˜¸ ê°•ë„)
    --------------------------------------------------------------

    âš ï¸ ì¤‘ìš”:
    - ì´ weightëŠ” "í™•ë¥ "ì„ ë§Œë“¤ì§€ ì•ŠëŠ”ë‹¤.
    - ì˜¤ì§ 'ì´ ë²•ì•ˆì„ ì–¼ë§ˆë‚˜ ë¯¿ì„ ê²ƒì¸ê°€'ë§Œ ê²°ì •í•œë‹¤.
    """

    # ë°œì–¸ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì‹ ë¢° â†‘ (logë¡œ ì™„ë§Œí™”)
    speech_factor = math.log(1 + max(n_speeches, 1))

    # í˜‘ë ¥/ë¹„í˜‘ë ¥ì˜ ê°•ë„(|ê°’|)ë§Œ ë°˜ì˜, ë°©í–¥ì€ ì œì™¸
    signal_strength = 1 + alpha * abs(avg_score_prob)

    return similarity * speech_factor * signal_strength


# ======================================================================
# MAIN PREDICTION FUNCTION
# ======================================================================
def predict_bill_pass_probability(query_text: str) -> Dict:
    """
    ë‹¨ì¼ ë²•ì•ˆ í‚¤ì›Œë“œ ì…ë ¥ â†’
    ê°€ê²° í™•ë¥  + ì…ë²• ê´´ë¦¬ìœ¨ + ì‹ ë¢°ë„ + ì„¤ëª… + ê·¼ê±° ë°˜í™˜
    """

    # --------------------------------------------------
    # 1) í•™ìŠµ ë°ì´í„° ë¡œë“œ
    # --------------------------------------------------
    bill_df = pd.read_pickle(TRAIN_PKL)

    # --------------------------------------------------
    # 2) ì¿¼ë¦¬ ì„ë² ë”©
    # --------------------------------------------------
    query_embedding = embed_query(query_text)

    # --------------------------------------------------
    # 3) ìœ ì‚¬ ë²•ì•ˆ ê²€ìƒ‰
    # --------------------------------------------------
    candidates = search_similar_bills(
        query_embedding=query_embedding,
        bill_df=bill_df,
        strict_threshold=0.60,
        soft_threshold=0.45,
        min_evidence=5
    )

    if candidates.empty:
        return {
            "query": query_text,
            "predicted_pass_probability": None,
            "legislative_gap": None,
            "confidence": None,
            "explanation": "ìœ ì‚¬í•œ ê³¼ê±° ë²•ì•ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "evidence_bills": []
        }

    # --------------------------------------------------
    # 4) ê·¼ê±° ë²•ì•ˆ ì •ë¦¬ + ê°€ì¤‘í•©
    # --------------------------------------------------
    weighted_sum = 0.0
    weight_total = 0.0
    evidence = []

    for _, r in candidates.iterrows():
        w = compute_weight(
            r.similarity,
            r.n_speeches,
            r.avg_score_prob
        )

        weighted_sum += w * r.label
        weight_total += w

        evidence.append({
            "bill_number": r.bill_number,
            "bill_name": r.bill_name,
            "avg_score_prob": r.avg_score_prob,
            "n_speeches": int(r.n_speeches),
            "label": int(r.label),
            "similarity": round(r.similarity, 4),
            "stance": (
                "í˜‘ë ¥" if r.avg_score_prob > 0.05 else
                "ë¹„í˜‘ë ¥" if r.avg_score_prob < -0.05 else
                "ì¤‘ë¦½"
            )
        })

    # --------------------------------------------------
    # 5) ê°€ê²° í™•ë¥  ê³„ì‚° (â­ ìµœì¢… ì„¤ê³„)
    # --------------------------------------------------

    # (A) ì‹¤ì œ ê³¼ê±° ì„±ê³¼ ê¸°ë°˜ í™•ë¥ 
    data_pass_prob = weighted_sum / weight_total if weight_total > 0 else 0.5

    # (B) ë…¼ì˜ ë¶„ìœ„ê¸° ê¸°ë°˜ ê¸°ëŒ€ì¹˜
    avg_coop = np.mean([e["avg_score_prob"] for e in evidence])
    coop_expectation = (avg_coop + 1) / 2   # -1~1 â†’ 0~1

    # (C) ë…¼ì˜ ì‹ ë¢°ë„ (ë°œì–¸ ìˆ˜ ê¸°ë°˜)
    total_speeches = sum(e["n_speeches"] for e in evidence)

    # ë°œì–¸ 0 â†’ 0 / ë°œì–¸ ì¶©ë¶„ â†’ 1
    speech_confidence = min(
        math.log(1 + total_speeches) / math.log(1 + 1000),
        1.0
    )

    # (D) ë…¼ì˜ ê¸°ë°˜ í™•ë¥ 
    # ë°œì–¸ì´ ì ìœ¼ë©´ ì¤‘ë¦½(0.5)ë¡œ íšŒê·€
    discussion_based_prob = (
        speech_confidence * coop_expectation +
        (1 - speech_confidence) * 0.5
    )

    # (E) â­ ìµœì¢… ê°€ê²° í™•ë¥ 
    # ë°œì–¸ì´ ë§ì„ìˆ˜ë¡:
    # - ì‹¤ì œ ì„±ê³¼(60%)
    # - ë…¼ì˜ ë¶„ìœ„ê¸°(40%)
    pass_prob = (
        (1 - speech_confidence) * 0.5 +
        speech_confidence * (
            0.6 * data_pass_prob +
            0.4 * discussion_based_prob
        )
    )

    # ì•ˆì „ í´ë¦¬í•‘ (0% / 100% ë°©ì§€)
    pass_prob = max(0.01, min(pass_prob, 0.99))

    # --------------------------------------------------
    # 6) ì…ë²• ê´´ë¦¬ìœ¨ ê³„ì‚° (â­ ìµœì¢… ì² í•™ ë°˜ì˜ - ì—°ì† ë°©í–¥ ëª¨ë¸)
    # --------------------------------------------------
    # í•µì‹¬ ì² í•™ ìš”ì•½:
    # 1) ê´´ë¦¬ëŠ” "ë…¼ì˜ ê¸°ëŒ€ vs ì‹¤ì œ ê²°ê³¼ì˜ ê±°ë¦¬"ì—ì„œ ì¶œë°œí•œë‹¤
    # 2) í•˜ì§€ë§Œ ê·¸ ê±°ë¦¬ê°€ ì˜ë¯¸ë¥¼ ê°€ì§€ë ¤ë©´,
    #    - ë…¼ì˜ ë°©í–¥ì´ ì–¼ë§ˆë‚˜ ëª…í™•í–ˆëŠ”ì§€ê°€ ì¤‘ìš”í•˜ë‹¤
    # 3) ë”°ë¼ì„œ ê´´ë¦¬ìœ¨ì€ ì•„ë˜ 3ìš”ì†Œì˜ ê³±ìœ¼ë¡œ ì •ì˜ëœë‹¤
    #
    #   ê´´ë¦¬ìœ¨ =
    #     |ë…¼ì˜ ê¸°ëŒ€ì¹˜ - ì‹¤ì œ ê²°ê³¼|
    #     Ã— ë…¼ì˜ ì‹ ë¢°ë„(ë°œì–¸ëŸ‰)
    #     Ã— ë°©í–¥ ëª…í™•ë„(í˜‘ë ¥ vs ë¹„í˜‘ë ¥ì˜ ë¶„ëª…í•¨)
    #
    # â€» ì¤‘ë¦½ì´ ë§ìœ¼ë©´ â†’ ë°©í–¥ ëª…í™•ë„ â†“ â†’ ê´´ë¦¬ ìë™ ê°ì†Œ
    # â€» ë°œì–¸ì´ ë§ìœ¼ë©´ â†’ ë…¼ì˜ ì‹ ë¢°ë„ â†‘ â†’ ê´´ë¦¬ ì¦í­ ê°€ëŠ¥
    # --------------------------------------------------

    # (0) ì‹¤ì œ í†µê³¼ ë¹„ìœ¨ (0~1)
    real_pass_rate = np.mean([e["label"] for e in evidence])

    # (1) ê¸°ë³¸ ê´´ë¦¬ í¬ê¸°: ê¸°ëŒ€ì™€ ê²°ê³¼ì˜ ê±°ë¦¬
    # - í˜‘ë ¥ ê¸°ëŒ€(coop_expectation)ì™€ ì‹¤ì œ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ì–´ê¸‹ë‚¬ëŠ”ê°€
    raw_gap = abs(coop_expectation - real_pass_rate)

    # --------------------------------------------------
    # (2) ë°©í–¥ ëª…í™•ë„ ê³„ì‚° (â­ í•µì‹¬ ê°œì„  í¬ì¸íŠ¸)
    # --------------------------------------------------
    # í˜‘ë ¥/ë¹„í˜‘ë ¥ ë°œì–¸ì´
    # "ì–¼ë§ˆë‚˜ ë¶„ëª…í•˜ê²Œ í•œìª½ìœ¼ë¡œ ê¸°ìš¸ì–´ ìˆì—ˆëŠ”ê°€?"ë¥¼ ìˆ˜ì¹˜í™”í•œë‹¤.

    coop_strength = sum(
        e["n_speeches"] * abs(e["avg_score_prob"])
        for e in evidence
        if e["avg_score_prob"] > 0.05
    )

    noncoop_strength = sum(
        e["n_speeches"] * abs(e["avg_score_prob"])
        for e in evidence
        if e["avg_score_prob"] < -0.05
    )

    direction_total = coop_strength + noncoop_strength

    if direction_total == 0:
        # ì „ë¶€ ì¤‘ë¦½ì— ê°€ê¹Œìš´ ê²½ìš° â†’ ë°©í–¥ì„± ê±°ì˜ ì—†ìŒ
        direction_confidence = 0.0
    else:
        # 0 ~ 1
        # 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ í•œìª½ ë°©í–¥ì´ ë§¤ìš° ëª…í™•
        direction_confidence = abs(coop_strength - noncoop_strength) / direction_total

    # --------------------------------------------------
    # (3) ìµœì¢… ì…ë²• ê´´ë¦¬ìœ¨
    # --------------------------------------------------
    legislative_gap = (
        raw_gap *
        speech_confidence *
        direction_confidence
    )

    # --------------------------------------------------
    # 6-1) ê´´ë¦¬ ìˆ˜ì¤€ êµ¬ê°„í™” (ì˜ë¯¸ ê¸°ë°˜)
    # --------------------------------------------------
    if legislative_gap < 0.08:
        gap_level = "ìµœí•˜"   # ë…¼ì˜ì™€ ê²°ê³¼ê°€ ê±°ì˜ ì¼ì¹˜
    elif legislative_gap < 0.18:
        gap_level = "í•˜"     # ì•½í•œ ë¶ˆì¼ì¹˜
    elif legislative_gap < 0.30:
        gap_level = "ì¤‘"     # ì˜ë¯¸ ìˆëŠ” ê´´ë¦¬
    elif legislative_gap < 0.45:
        gap_level = "ìƒ"     # êµ¬ì¡°ì  ê´´ë¦¬
    else:
        gap_level = "ìµœìƒ"   # ì‹¬ê°í•œ ì…ë²• ê´´ë¦¬


    # --------------------------------------------------
    # 7) ì‹ ë¢°ë„ ê³„ì‚°
    # --------------------------------------------------
    avg_similarity = np.mean([e["similarity"] for e in evidence])

    confidence_score = round(
        0.4 * min(len(evidence) / 10, 1.0) +
        0.4 * avg_similarity +
        0.2 * min(weight_total / 5.0, 1.0),
        3
    )

    confidence_level = (
        "ë†’ìŒ" if confidence_score >= 0.7 else
        "ë³´í†µ" if confidence_score >= 0.4 else
        "ë‚®ìŒ"
    )

    # --------------------------------------------------
    # 8) ì„¤ëª… ìƒì„±
    # --------------------------------------------------
    stance = (
        "í˜‘ë ¥ ìš°ì„¸" if avg_coop > 0.03 else
        "ë¹„í˜‘ë ¥ ìš°ì„¸" if avg_coop < -0.03 else
        "ì¤‘ë¦½"
    )

    explanation = (
        f"ì…ë ¥ëœ ë²•ì•ˆ '{query_text}'ì€(ëŠ”) "
        f"ê³¼ê±° ìœ ì‚¬ ë²•ì•ˆ {len(evidence)}ê±´, "
        f"ì´ {total_speeches}íšŒì˜ ë°œì–¸ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤. "
        f"ì „ì²´ ë…¼ì˜ ë¶„ìœ„ê¸°ëŠ” '{stance}'ì´ë©°, "
        f"ì…ë²• ê´´ë¦¬ ìˆ˜ì¤€ì€ '{gap_level}'ë¡œ í‰ê°€ë©ë‹ˆë‹¤."
    )

    # --------------------------------------------------
    # 9) ë°˜í™˜
    # --------------------------------------------------
    return {
        "query": query_text,
        "predicted_pass_probability": round(pass_prob, 4),
        "legislative_gap": {
            "score": round(legislative_gap, 4),
            "level": gap_level
        },
        "confidence": {
            "score": confidence_score,
            "level": confidence_level
        },
        "explanation": explanation,
        "evidence_bills": evidence
    }


# ======================================================================
# CLI INTERFACE
# ======================================================================
if __name__ == "__main__":

    print("\n======================================")
    print("ğŸ“Š ë²•ì•ˆ í†µê³¼ ê°€ëŠ¥ì„± ë¶„ì„ê¸°")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥")
    print("======================================\n")

    while True:
        query = input("ğŸ” ë²•ì•ˆ í‚¤ì›Œë“œ ì…ë ¥ > ").strip()

        if query.lower() in ("exit", "quit"):
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        result = predict_bill_pass_probability(query)

        print("\n[ì˜ˆì¸¡ ê²°ê³¼]")
        print(f"ê°€ê²° í™•ë¥ : {result['predicted_pass_probability']}")
        print(f"ì…ë²• ê´´ë¦¬ìœ¨: {result['legislative_gap']}")
        print(f"ì‹ ë¢°ë„: {result['confidence']}")

        print("\n[ì„¤ëª…]")
        print(result["explanation"])

        print("\n[ê·¼ê±° ë²•ì•ˆ]")
        for i, e in enumerate(result["evidence_bills"], 1):
            result_str = "í†µê³¼" if e["label"] == 1 else "ë¶ˆí†µê³¼"
            print(
                f"{i}. {e['bill_name']} "
                f"(ì˜ì•ˆë²ˆí˜¸: {e['bill_number']}) | "
                f"ë…¼ì˜íƒœë„: {e['stance']} | "
                f"ì˜ê²°ê²°ê³¼: {result_str} | "
                f"ë²•ì•ˆìœ ì‚¬ë„ {e['similarity']}"
            )

        print("\n--------------------------------------\n")
